import numpy as npimport torchimport torch.autograd as autogradfrom torch import nn, optimfrom torch.autograd import Variableimport torch.nn.functional as Fclass LSTMTagger(nn.Module):    '''    recurrent neural network    '''    def __init__(self, node_size, input_dim, hidden_dim, out_dim, pre_embedding, nonlinearity='relu', n_layers=1,                 dropout=0.2):        super(LSTMTagger, self).__init__()        self.node_size = node_size        self.input_dim = input_dim        self.hidden_dim = hidden_dim  # 32        self.out_dim = out_dim        self.pre_embedding = pre_embedding        self.embedding = nn.Embedding(node_size, input_dim)  # 所有节点(n*input_dim)        # self.embedding.weight = nn.Parameter(pre_embedding)        self.lstm = nn.LSTM(input_dim, hidden_dim)        self.linear = nn.Linear(hidden_dim + self.input_dim * 2, out_dim, bias=True)        self.mlp2layer = nn.Sequential(nn.Linear(2 * input_dim, hidden_dim),                                       nn.ReLU(),                                       nn.Linear(hidden_dim, 10))        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, dropout=dropout)    # 	每个user的前项反馈，数据输入    def forward(self, paths_between_one_pair):        """        :param paths_between_one_pair: 模型的输入函数        :return: 预测值        思路：用户和项目的交互影响            具体做法是：                mlp(user * item) = mlp (50,(bathch_size * 10 )*(batch_size * 10))) 输出是50维                LSTM 取每条交互序列的第一个和最后一个输出作为用户和项目的更新函数。                融合这些特征就可以获得用户和项目的特征向量，最后使用点积的形式获得预测的函数        """        # paths_between_one_pair_id 是输入数据        paths_between_one_pair_id = paths_between_one_pair[0]        user_id = paths_between_one_pair[1]  # user_id        item_id = paths_between_one_pair[2]  # item_id        print(user_id)        print(item_id)        # user_list_id = paths_between_one_pair[1]        # print(user_list_id)        # u_len = len(user_list_id)        # item_list_id = paths_between_one_pair[2]        # print(paths_between_one_pair_id)        sum_hidden = Variable(torch.Tensor(), requires_grad=True)        user_upg = Variable(torch.Tensor(), requires_grad=True)        item_upg = Variable(torch.Tensor(), requires_grad=True)        paths_size = len(paths_between_one_pair_id)  # user-item之间存在的路径        # user_embedding = self.embedding(user_list_id)        # user_embedding = user_embedding.view(u_len, 1, self.input_dim)        # print("user_embedding维度"+str(user_embedding.shape))#(4,10)        # item_embedding = self.embedding(item_list_id)        # item_embedding = item_embedding.view(u_len, 1, self.input_dim)        # print(paths_size)        for i in range(paths_size):  # 遍历每条路径            path = paths_between_one_pair_id[i]   #path=tensor([ 0,  1,  4,  3], device='cuda:0')            path_size = len(path)  # 路径长度            # print(path_size)s            # 获取用户节点的输出向量            for k, node in enumerate(path.cpu().numpy().tolist()):  #提取每条路径的一个节点的隐藏向量作为user的影响                node=torch.Tensor([node])                if torch.cuda.is_available():                    node=node.cuda()                node_embedding = self.embedding(node)                node_embedding = node_embedding.view(1, 1, -1)                if torch.cuda.is_available():                    node_embedding = node_embedding.cuda()                node_out, h_node = self.lstm(node_embedding)                # 保存每条路径的第一个节点user和最后一个节点item                if (i == 0 and k==0):                    user_upg = h_node[0]                    continue                elif k == 0:                    user_upg = torch.cat((user_upg, h_node[0]), 1)  # 拼接的是 path_size * hidden_dim            path_embedding = self.embedding(path)            # 转换隐向量的维度            path_embedding = path_embedding.view(path_size, 1, self.input_dim)            # print(path_embedding.shape)		#(2,1,10)            if torch.cuda.is_available():                path_embedding = path_embedding.cuda()            # user_embedding = user_embedding.cuda()            # item_embedding = item_embedding.cuda()            path_out, h = self.lstm(path_embedding)            # print("隐向量的维度："+str(h[0].shape))	#此时的隐特征的维度(1,1,16)            # print("序列输出维度大小："+str(path_out.shape))	#(2,1,16)            # 返回的隐藏层的向量 sum_hidden = path_size * 32            if i == 0:                item_upg = h[0]                sum_hidden = h[0]            else:  # 返回的是所有路径的隐语义向量                item_upg = torch.cat((item_upg, h[0]), 1)                sum_hidden = torch.cat((sum_hidden, h[0]), 0)        # print(sum_hidden.shape)		#2,1, pool = nn.MaxPool2d((1,16))16        user_liner = torch.nn.Linear(32, 16).cpu()        item_liner = torch.nn.Linear(32, 16).cpu()        user_upg = user_liner(user_upg)        item_upg = item_liner(item_upg)        # 交互影响的获取        user_emb = self.embedding(user_id)        item_emb = self.embedding(item_id)        # 实现是拼接，可以使用内积+mlp形式实现        cat = torch.cat((user_emb, item_emb), 1)  # 行拼接，（1，20）        # cat = torch.mul((user_emb, item_emb))        # mlp        cat = self.mlp2layer(cat)  # (1,20)        # cat = cat.view(1, self.input_dim * 2)        # print(cat.shape)        item_pool = nn.MaxPool2d((1, self.hidden_dim))  #        # user_pool = nn.MaxPool2d((1, self.hidden_dim))        # pool = nn.MaxPool2d((paths_size,1),(paths_size,1))        # adp_pool = nn.AdaptiveAvgPool1d((1,self.hidden_dim))        att = item_pool(sum_hidden)        att = F.softmax(att, dim=0)        # print(att.shape)        # print(att.shape)		#2,1,1        # max_pool = max_pool.view(paths_size,1,1)        path_extract = torch.mul(sum_hidden, att)  # 1,32        path_emb = torch.sum(path_extract, 0, True)  # 1,32        path_extract = path_emb.view(1, -1)  # (1, 32)        # user item 特征融合        cat=cat.view(1,-1)        user_upg=user_upg.view(1,-1)        user_upg=user_upg.cuda()        item_upg = item_upg.view(1,-1)        item_upg = item_upg.cuda()        user = torch.cat((cat, user_upg), -1)        user = torch.cat((user, path_extract), -1)  #26+32=58        item = torch.cat((cat, item_upg), -1)        item = torch.cat((item, path_extract), -1)        pre0 = torch.cat((user, item), -1) #58+58=116        prediction_layer = torch.nn.Sequential(nn.Linear(pre0.size()[1], 16),                                               nn.Linear(16, 8),                                               nn.Linear(8, self.out_dim),                                               nn.Sigmoid()).cuda()        pre = prediction_layer(pre0)        # emb = torch.cat((cat, path_extract), -1)        # print(emb.shape)        # emb = nn.Linear(self.input_dim*2+self.hidden_dim,self.hidden_dim,bias=True)(emb)        # print(path_emb.shape)        # print(path_extract.shape)        # path_emb = path_extract.view(1,-1,self.hidden_dim)        # print(path_emb.shape)        # path_extract = F.softmax(path_extract,dim=0)        # path_emb_pool = nn.MaxPool2d((paths_size,1),stride=(paths_size,1))        # path_emb = path_emb_pool(path_extract)        # print(max_pool.shape)	(1,1,16)        # print(path_emb.shape)        # user和item序列语义的提取        # u_out, _ = self.lstm_u(user_embedding)        # i_out, _ = self.lstm_i(item_embedding)        # u_out = u_out.view(1,u_len*self.hidden_dim)	#(1,64)        # i_out = i_out.view(1,u_len*self.hidden_dim)        # 对用户序列的输出和项目的近期输出(4,1,16)*(4,1,16)        # print(u_out.shape)		#(4,1,16)        # ui = u_out.mul(i_out)        # ui = ui.view(1,1,-1)        # print(ui.shape)		(1,1,64)        # ui_out = self.dnn(ui)	#(1,1,1)        # out = self.linear(emb)  # （1,1,1）        # out = out + ui_out        # out = F.sigmoid(out)        # 两个结果的        return pre